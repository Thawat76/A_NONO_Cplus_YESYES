{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BEE\\Downloads\\010723305-main./new-camera_params\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\BEE\\\\Downloads\\\\010723305-main./new-camera_paramsK.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20680/2132846874.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;31m#load camera parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'K.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'dist.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\BEE\\\\Downloads\\\\010723305-main./new-camera_paramsK.npy'"
     ]
    }
   ],
   "source": [
    "#VERSION 3.8.10\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pylab as plt\n",
    "from skimage import io\n",
    "\n",
    "\n",
    "img = cv2.imread(\"./images/final_exam/Templates/Template-1.png\", 0)  \n",
    "cap = cv2.VideoCapture(\"./videos/final_exam/Dataset-1/left_output-1.avi\", 0)\n",
    "\n",
    "\n",
    "\n",
    "# Features\n",
    "\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kp_image, desc_image = sift.detectAndCompute(img, None)\n",
    "fl = cv2.flann\n",
    "bf = cv2.BFMatcher\n",
    "\n",
    "\n",
    "# matching\n",
    "index_params = dict(algorithm=0, trees=5)\n",
    "search_params = dict()\n",
    "bf = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "\n",
    "while cap.isOpened() :\n",
    "\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  \n",
    "    kp_grayframe, desc_grayframe = sift.detectAndCompute(grayframe, None)\n",
    "    matches = bf.knnMatch(desc_image, desc_grayframe, k=2)\n",
    "    good_points = []\n",
    "   \n",
    "\n",
    "\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.79999 * n.distance:\n",
    "            good_points.append(m)\n",
    "\n",
    "\n",
    "            \n",
    "    # img3 = cv2.drawMatches(img, kp_image, grayframe, kp_grayframe, good_points, grayframe)\n",
    "\n",
    "\n",
    "\n",
    "    # Homo\n",
    "\n",
    "\n",
    "    if len(good_points) > 10:\n",
    "\n",
    "\n",
    "        query_pts = np.float32([kp_image[m.queryIdx].pt for m in good_points]).reshape(-1, 1, 2)\n",
    "        train_pts = np.float32([kp_grayframe[m.trainIdx].pt for m in good_points]).reshape(-1, 1, 2)\n",
    "        matrix, mask = cv2.findHomography(query_pts, train_pts, cv2.RANSAC, 0.5)\n",
    "        matches_mask = mask.ravel().tolist()\n",
    "\n",
    "\n",
    "        # transform\n",
    "\n",
    "\n",
    "        h, w = img.shape\n",
    "        point = np.float32([[0, 0], [0, h], [w, h], [w, 0]]).reshape(-1, 1, 2)\n",
    "        dest = cv2.perspectiveTransform(point, matrix)\n",
    "        LASTDETECT = cv2.polylines(frame, [np.int32(dest)], True, (255, 0, 0), 3)\n",
    "        cv2.imshow(\"Homography\", LASTDETECT)\n",
    "\n",
    "        \n",
    "    else:\n",
    "        cv2.imshow(\"Homography\", grayframe)\n",
    "        # cv2.imshow(\"Image\", img)\n",
    "        # cv2.imshow(\"grayFrame\", grayframe)\n",
    "        # cv2.imshow(\"img3\", img3)\n",
    "    key = cv2.waitKey(35) & 0xFF\n",
    "    if key == 27 or key == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "#หลังจากนี้กระผมทำไม่ได้เเล้วขอรับ\n",
    "\n",
    "################################################################################################\n",
    "params_dir = os.getcwd()+'./new-camera_params'\n",
    "print(params_dir)\n",
    "\n",
    "#load camera parameters\n",
    "K = np.load(params_dir+'K.npy')\n",
    "dist = np.load(params_dir+'dist.npy')\n",
    "\n",
    "print(\"Camera matrix\")\n",
    "print(K)\n",
    "print(\"Len distortion\")\n",
    "print(dist)\n",
    "def augmented_image(frame,im_src, pts_src, pts_dst):\n",
    "    \n",
    "    # Calculate Homography\n",
    "    h, status = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "    # Warp source image to destination based on homography\n",
    "    warped_image = cv2.warpPerspective(im_src, h, (frame.shape[1],frame.shape[0]))\n",
    "            \n",
    "    # Prepare a mask representing region to copy from the warped image into the original frame.\n",
    "    mask = np.zeros([frame.shape[0], frame.shape[1]], dtype=np.uint8)\n",
    "    cv2.fillConvexPoly(mask, np.int32(pts_dst), (255, 255, 255), cv2.LINE_AA)\n",
    "    im_out = cv2.add(frame, warped_image, mask=cv2.bitwise_not(mask))\n",
    "    im_out = cv2.add(im_out, warped_image)\n",
    "    \n",
    "    return im_out\n",
    "def write_text(img, pose, dy, text) :\n",
    "    x0 = pose[0]\n",
    "    y0 = pose[1]\n",
    "    for i, line in enumerate(text.split('\\n')) :\n",
    "        y = y0 + i*dy\n",
    "        cv2.putText(img, line, np.int32([x0, y]), cv2.FONT_HERSHEY_COMPLEX, 0.75, (50,200,255), 2)\n",
    "        markerCorners, markerIds, rejectedCandidates = cv2.aruco.detectMarkers(frame, AruCo_dict, parameters = AruCo_params)\n",
    "        \n",
    "        if len(markerCorners) > 0:\n",
    "            img = cv2.aruco.drawDetectedMarkers(frame, markerCorners)\n",
    "            rvecs, tvecs, points = cv2.aruco.estimatePoseSingleMarkers(markerCorners , 0.05, K, dist)\n",
    "            for (rvec, tvec, id, corner) in zip(rvecs, tvecs, markerIds, markerCorners) :\n",
    "                img = cv2.aruco.drawAxis(frame, K, dist, rvec, tvec, 0.05)\n",
    "                x = tvec[0,0]\n",
    "                y = tvec[0,1]\n",
    "                z = tvec[0,2]\n",
    "                text = \"id: {}\\n pose:\\n {:.3f}\\n {:.3f}\\n {:.3f}\".format(id, x, y, z)\n",
    "                cX = (corner[0,0][0] + corner[0,2][0]) / 2\n",
    "                cY = (corner[0,0][1] + corner[0,2][1]) / 2\n",
    "                write_text(img, (cX, cY), 20, text)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_dir = os.getcwd()+'/camera_params/monocular_camera_params/'\n",
    "# print(params_dir)\n",
    "\n",
    "# #load camera parameters\n",
    "# K = np.load(params_dir+'K.npy')\n",
    "# dist = np.load(params_dir+'dist.npy')\n",
    "\n",
    "# print(\"Camera matrix\")\n",
    "# print(K)\n",
    "# print(\"Len distortion\")\n",
    "# print(dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def augmented_image(frame,im_src, pts_src, pts_dst):\n",
    "    \n",
    "#     # Calculate Homography\n",
    "#     h, status = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "#     # Warp source image to destination based on homography\n",
    "#     warped_image = cv2.warpPerspective(im_src, h, (frame.shape[1],frame.shape[0]))\n",
    "            \n",
    "#     # Prepare a mask representing region to copy from the warped image into the original frame.\n",
    "#     mask = np.zeros([frame.shape[0], frame.shape[1]], dtype=np.uint8)\n",
    "#     cv2.fillConvexPoly(mask, np.int32(pts_dst), (255, 255, 255), cv2.LINE_AA)\n",
    "#     im_out = cv2.add(frame, warped_image, mask=cv2.bitwise_not(mask))\n",
    "#     im_out = cv2.add(im_out, warped_image)\n",
    "    \n",
    "#     return im_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_text(img, pose, dy, text) :\n",
    "#     x0 = pose[0]\n",
    "#     y0 = pose[1]\n",
    "#     for i, line in enumerate(text.split('\\n')) :\n",
    "#         y = y0 + i*dy\n",
    "#         cv2.putText(img, line, np.int32([x0, y]), cv2.FONT_HERSHEY_COMPLEX, 0.75, (50,200,255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  markerCorners, markerIds, rejectedCandidates = cv2.aruco.detectMarkers(frame, AruCo_dict, parameters = AruCo_params)\n",
    "        \n",
    "#         if len(markerCorners) > 0:\n",
    "#             img = cv2.aruco.drawDetectedMarkers(frame, markerCorners)\n",
    "#             rvecs, tvecs, points = cv2.aruco.estimatePoseSingleMarkers(markerCorners , 0.05, K, dist)\n",
    "#             for (rvec, tvec, id, corner) in zip(rvecs, tvecs, markerIds, markerCorners) :\n",
    "#                 img = cv2.aruco.drawAxis(frame, K, dist, rvec, tvec, 0.05)\n",
    "#                 x = tvec[0,0]\n",
    "#                 y = tvec[0,1]\n",
    "#                 z = tvec[0,2]\n",
    "#                 text = \"id: {}\\n pose:\\n {:.3f}\\n {:.3f}\\n {:.3f}\".format(id, x, y, z)\n",
    "#                 cX = (corner[0,0][0] + corner[0,2][0]) / 2\n",
    "#                 cY = (corner[0,0][1] + corner[0,2][1]) / 2\n",
    "#                 write_text(img, (cX, cY), 20, text)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "025f5ad4b29486a94fba4c051c42dc27f0a7c9fc1360b082ed17256a45f4d18e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
